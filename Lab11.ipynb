{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+DAbS5ZBRyJk9BkphbgQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glorivaas/Machine_Learning25/blob/main/Lab11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**HOMEWORK 11**\n",
        "##**Understanding Deconvolution in Autoencoders**"
      ],
      "metadata": {
        "id": "fuywdbk6LC87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Theoretical part**\n",
        "\n",
        "1. **What is a transposed convolution?**\n",
        "\n",
        " A transposed convolution (also called deconvolution) is a layer that reverses the spatial effects of a standard convolution.\n",
        " Its goal is to upsample a smaller input feature map into a larger output. It is often used in the field of autoencoders (in the decoder), GANs (to generate images), U-Net (to recover spatial resolution).\n",
        "  \n",
        "  We can think of it as answering the following question: \"How do we reconstruct a larger image that might have been downsampled by a convolution before?\"\n",
        "\n",
        "\n",
        "2. **How does it differ from a regular convolution?**\n",
        "\n",
        " The goal of a regular convolution is to downsample, or reduce the size of the input (which are larger elements than the output), whereas transposed convolution focuses on upsampling, or increasing the size of the inputs. Moreover, their usses differ, being mainly encoding (feaure extraction) for regular convolution and decoding (reconstruction, generation) for transposed one.\n",
        " Their way of operating is also different: in regular convolution, the kernel compresses information into smaller areas. In transposed convolution, we apply the kernel in a way that distributes the input values over a larger space, effectively expanding it.\n",
        "\n",
        "\n",
        "3. **How does it upsample feature maps?**\n",
        "\n",
        " The main steps for increasing the spatial dimensions of an input tensor are the following:\n",
        "  1. Insert zeros between elements (depending on stride).\n",
        "\n",
        "  2. Slide a kernel over this expanded input.\n",
        "\n",
        "  3. Multiply and sum values just like in convolution.\n",
        "\n",
        "  4. Overlap adds up: multiple kernel applications can contribute to the same output position.\n",
        "\n",
        "  5. The result is an upsampled output grid with learned spatial structure.\n",
        "\n",
        "  Maybe it is clearer if we see an example for this.\n",
        "\n",
        "Input feature map: a 2D grid (e.g., size 2√ó2)\n",
        "\n",
        "Kernel: size 3√ó3\n",
        "\n",
        "Stride: 2\n",
        "\n",
        "Padding: 0\n",
        "\n",
        "We'll show what happens when we apply a transposed convolution.\n",
        "\n",
        "üß© Step 1: ‚ÄúInsert Zeros‚Äù ‚Äì Input Expansion\n",
        "In transposed convolution, the first step is to expand the input by inserting zeros between the elements. This depends on the stride.\n",
        "\n",
        "If stride = 2, insert (stride - 1) = 1 zero between each row and column.\n",
        "\n",
        "For example, for a 2√ó2 input:\n",
        "\n",
        "csharp\n",
        "Copiar\n",
        "Editar\n",
        "Input:\n",
        "[1 2]\n",
        "[3 4]\n",
        "\n",
        "Insert 1 zero between rows/cols:\n",
        "\n",
        "Expanded:\n",
        "[1 0 2]\n",
        "[0 0 0]\n",
        "[3 0 4]\n",
        "Now we have a 3√ó3 grid, where the non-zero values are the original inputs, and the rest are zeros.\n",
        "\n",
        "Note: With larger strides, more zeros are inserted.\n",
        "\n",
        "üßÆ Step 2: Slide the Kernel Over the Expanded Grid\n",
        "Next, we slide the kernel over this expanded grid ‚Äî just like in a regular convolution ‚Äî but now applying the kernel to these sparse inputs.\n",
        "\n",
        "Let‚Äôs say the kernel is:\n",
        "\n",
        "csharp\n",
        "Copiar\n",
        "Editar\n",
        "Kernel:\n",
        "[a b c]\n",
        "[d e f]\n",
        "[g h i]\n",
        "At each position, we perform the usual element-wise multiplication and summation between the kernel and the overlapping region in the expanded grid.\n",
        "\n",
        "For instance, the top-left region of the expanded grid might be multiplied with the kernel, and the sum is written into the output at a specific location.\n",
        "\n",
        "This step is why the operation is called ‚Äútransposed‚Äù ‚Äî mathematically, it's the gradient of a convolution, but operationally it \"spreads out\" the input.\n",
        "\n",
        "üßÆ Step 3: Sum Overlapping Contributions\n",
        "Because we are sliding the kernel over a grid that has inserted zeros and a stride of 1, some output positions will receive multiple contributions from different overlapping kernel applications.\n",
        "\n",
        "In those cases, we sum the values contributed by each overlapping region.\n",
        "\n",
        "This is essential to understand:\n",
        "\n",
        "Transposed convolution is not simply placing the input values further apart.\n",
        "\n",
        "It‚Äôs a learned upsampling process ‚Äî the values are combined based on kernel weights, just like a convolution but in reverse.\n",
        "\n",
        "üßæ Final Output\n",
        "The result is an output grid larger than the input. For example:\n",
        "\n",
        "If you start with a 2√ó2 input, a 3√ó3 kernel, and stride = 2, you may end up with a 5√ó5 output, depending on the padding and dilation.\n",
        "\n",
        "üìê Formula to Compute Output Size\n",
        "You can compute the spatial output size from:\n",
        "\n",
        "arduino\n",
        "Copiar\n",
        "Editar\n",
        "Output size = (Input size - 1) * stride - 2 * padding + kernel size\n",
        "For each dimension (height/width).\n",
        "\n",
        "Example:\n",
        "\n",
        "Input = 2\n",
        "\n",
        "Stride = 2\n",
        "\n",
        "Padding = 0\n",
        "\n",
        "Kernel size = 3\n",
        "\n",
        "Then:\n",
        "\n",
        "Copiar\n",
        "Editar\n",
        "(2 - 1) * 2 - 0 + 3 = 5\n",
        "So a 2√ó2 input becomes a 5√ó5 output.\n",
        "4. **What are stride, padding, and kernel size, and how do they influence the result in a transposed convolution?**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PKmMc0cTLYpp"
      }
    }
  ]
}